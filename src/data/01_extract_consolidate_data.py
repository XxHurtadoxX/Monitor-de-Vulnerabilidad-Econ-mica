#!/usr/bin/env python3
"""
ExtracciÃ³n y ConsolidaciÃ³n de Datos GEIH 2024
Monitor de Vulnerabilidad EconÃ³mica - Colombia

Este script extrae los datos de los 12 meses de 2024 de los archivos ZIP
y consolida todos los mÃ³dulos en un Ãºnico dataset.

MÃ³dulos GEIH:
1. CaracterÃ­sticas generales, seguridad social en salud y educaciÃ³n
2. Datos del hogar y la vivienda
3. Fuerza de trabajo
4. MigraciÃ³n
5. No ocupados
6. Ocupados
7. Otras formas de trabajo
8. Otros ingresos e impuestos
"""

import pandas as pd
import zipfile
import os
from pathlib import Path
import json
from datetime import datetime

# ConfiguraciÃ³n
RAW_DIR = Path("data/raw")
PROCESSED_DIR = Path("data/processed")
PROCESSED_DIR.mkdir(exist_ok=True)

# Mapeo de nombres de archivos ZIP a periodo
MONTH_MAPPING = {
    'Ene_2024.zip': 202401,
    'Febrero_2024.zip': 202402,
    'Marzo 2024.zip': 202403,
    'Abril 2024.zip': 202404,
    'Mayo_2024 1.zip': 202405,
    'Junio_2024.zip': 202406,
    'Julio_2024.zip': 202407,
    'Agosto_2024.zip': 202408,
    'Septiembre_2024.zip': 202409,
    'Octubre_2024.zip': 202410,
    'Noviembre_ 2024.zip': 202411,
    'Diciembre_2024.zip': 202412
}

# Nombres de mÃ³dulos
MODULE_NAMES = {
    'CaracterÃ­sticas generales, seguridad social en salud y educaciÃ³n.CSV': 'caracteristicas_generales',
    'Datos del hogar y la vivienda.CSV': 'datos_hogar',
    'Fuerza de trabajo.CSV': 'fuerza_trabajo',
    'MigraciÃ³n.CSV': 'migracion',
    'No ocupados.CSV': 'no_ocupados',
    'Ocupados.CSV': 'ocupados',
    'Otras formas de trabajo.CSV': 'otras_formas_trabajo',
    'Otros ingresos e impuestos.CSV': 'otros_ingresos'
}

# Identificadores segÃºn nivel de anÃ¡lisis
ID_COLUMNS = {
    'hogar': ['DIRECTORIO', 'SECUENCIA_P', 'HOGAR'],
    'persona': ['DIRECTORIO', 'SECUENCIA_P', 'ORDEN', 'HOGAR'],
    'mes': ['PERIODO']
}


def extract_module_from_zip(zip_path, module_name, periodo):
    """
    Extraer un mÃ³dulo especÃ­fico de un archivo ZIP
    
    Args:
        zip_path: Ruta al archivo ZIP
        module_name: Nombre del mÃ³dulo CSV
        periodo: Periodo (YYYYMM)
        
    Returns:
        DataFrame con los datos del mÃ³dulo
    """
    try:
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            # Buscar el archivo CSV dentro del ZIP
            csv_files = [f for f in zip_ref.namelist() if f.endswith('.CSV')]
            target_file = [f for f in csv_files if module_name in f]
            
            if not target_file:
                print(f"  âš  MÃ³dulo {module_name} no encontrado en {zip_path.name}")
                return None
            
            # Leer el CSV con codificaciÃ³n latin-1 y separador ;
            with zip_ref.open(target_file[0]) as file:
                df = pd.read_csv(file, encoding='latin-1', sep=';', low_memory=False)
                
                # Agregar columna PERIODO si no existe
                if 'PERIODO' not in df.columns:
                    df['PERIODO'] = periodo
                
                print(f"  âœ“ {module_name}: {df.shape[0]:,} registros, {df.shape[1]} columnas")
                return df
                
    except Exception as e:
        print(f"  âœ— Error extrayendo {module_name}: {e}")
        return None


def consolidate_module_across_months(module_name, module_key):
    """
    Consolidar un mÃ³dulo a travÃ©s de los 12 meses
    
    Args:
        module_name: Nombre del archivo CSV del mÃ³dulo
        module_key: Clave del mÃ³dulo (caracteristicas_generales, etc.)
        
    Returns:
        DataFrame consolidado del mÃ³dulo
    """
    print(f"\n{'='*60}")
    print(f"Consolidando mÃ³dulo: {module_key}")
    print(f"{'='*60}")
    
    all_data = []
    
    for zip_file, periodo in MONTH_MAPPING.items():
        zip_path = RAW_DIR / zip_file
        
        if not zip_path.exists():
            print(f"âš  Archivo no encontrado: {zip_file}")
            continue
        
        print(f"\nMes {periodo} ({zip_file}):")
        
        # Extraer mÃ³dulo
        df = extract_module_from_zip(zip_path, module_name, periodo)
        
        if df is not None:
            all_data.append(df)
    
    if not all_data:
        print(f"âœ— No se encontraron datos para {module_key}")
        return None
    
    # Concatenar todos los meses
    consolidated_df = pd.concat(all_data, ignore_index=True)
    
    print(f"\n{'â”€'*60}")
    print(f"TOTAL CONSOLIDADO: {consolidated_df.shape[0]:,} registros")
    print(f"Columnas: {consolidated_df.shape[1]}")
    print(f"Periodos: {sorted(consolidated_df['PERIODO'].unique())}")
    print(f"{'â”€'*60}")
    
    # No guardar mÃ³dulos intermedios, solo retornar para el merge
    return consolidated_df


def identify_module_level(df, module_key):
    """
    Identificar si el mÃ³dulo es a nivel hogar o persona
    
    Args:
        df: DataFrame del mÃ³dulo
        module_key: Clave del mÃ³dulo
        
    Returns:
        str: 'hogar' o 'persona'
    """
    # MÃ³dulos a nivel hogar (no tienen ORDEN)
    hogar_modules = ['datos_hogar']
    
    if module_key in hogar_modules or 'ORDEN' not in df.columns:
        return 'hogar'
    else:
        return 'persona'


def merge_all_modules(modules_data):
    """
    Hacer merge de todos los mÃ³dulos consolidados
    
    Args:
        modules_data: Diccionario con los mÃ³dulos consolidados
        
    Returns:
        DataFrame con todos los mÃ³dulos unidos
    """
    print(f"\n{'='*60}")
    print(f"MERGE DE TODOS LOS MÃ“DULOS")
    print(f"{'='*60}")
    
    # Mostrar informaciÃ³n de los mÃ³dulos
    for module_key, module_info in modules_data.items():
        df = module_info['data']
        level = module_info['level']
        print(f"\n{module_key}:")
        print(f"  Nivel: {level}")
        print(f"  Shape: {df.shape}")
    
    # Empezar con el mÃ³dulo de caracterÃ­sticas generales (nivel persona)
    print(f"\n{'â”€'*60}")
    print("Iniciando merge desde caracterÃ­sticas generales...")
    print(f"{'â”€'*60}")
    
    base_df = modules_data['caracteristicas_generales']['data'].copy()
    print(f"\nBase inicial: {base_df.shape}")
    
    # Merge con datos del hogar (nivel hogar)
    if 'datos_hogar' in modules_data:
        hogar_df = modules_data['datos_hogar']['data']
        
        # IDs para merge a nivel hogar
        merge_keys_hogar = ['DIRECTORIO', 'SECUENCIA_P', 'HOGAR', 'PERIODO']
        
        print(f"\nMerge con datos_hogar (nivel hogar)...")
        base_df = base_df.merge(
            hogar_df,
            on=merge_keys_hogar,
            how='left',
            suffixes=('', '_hogar')
        )
        print(f"Shape despuÃ©s del merge: {base_df.shape}")
    
    # Merge con mÃ³dulos a nivel persona
    persona_modules = [k for k, v in modules_data.items() 
                      if k not in ['caracteristicas_generales', 'datos_hogar'] 
                      and v['level'] == 'persona']
    
    merge_keys_persona = ['DIRECTORIO', 'SECUENCIA_P', 'ORDEN', 'HOGAR', 'PERIODO']
    
    for module_key in persona_modules:
        print(f"\nMerge con {module_key} (nivel persona)...")
        module_df = modules_data[module_key]['data']
        
        base_df = base_df.merge(
            module_df,
            on=merge_keys_persona,
            how='left',
            suffixes=('', f'_{module_key}')
        )
        print(f"Shape despuÃ©s del merge: {base_df.shape}")
    
    print(f"\n{'â”€'*60}")
    print(f"MERGE FINAL COMPLETADO")
    print(f"Shape final: {base_df.shape}")
    print(f"Registros totales: {base_df.shape[0]:,}")
    print(f"Columnas totales: {base_df.shape[1]:,}")
    print(f"{'â”€'*60}")
    
    # Guardar dataset consolidado
    output_file = PROCESSED_DIR / "geih_2024_consolidated.csv"
    base_df.to_csv(output_file, index=False, encoding='utf-8')
    print(f"\nâœ“ Dataset consolidado guardado en: {output_file}")
    
    # Guardar resumen
    summary = {
        'fecha_consolidacion': datetime.now().isoformat(),
        'total_registros': int(base_df.shape[0]),
        'total_columnas': int(base_df.shape[1]),
        'periodos': sorted([int(p) for p in base_df['PERIODO'].unique()]),
        'modulos_incluidos': list(modules_data.keys()),
        'valores_nulos_por_columna': base_df.isnull().sum().to_dict(),
        'tipos_datos': base_df.dtypes.astype(str).to_dict()
    }
    
    with open(PROCESSED_DIR / 'consolidation_summary.json', 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False, default=str)
    
    print(f"âœ“ Resumen guardado en: {PROCESSED_DIR / 'consolidation_summary.json'}")
    
    return base_df


def main():
    """
    FunciÃ³n principal
    """
    print("="*70)
    print("EXTRACCIÃ“N Y CONSOLIDACIÃ“N DE DATOS GEIH 2024")
    print("Monitor de Vulnerabilidad EconÃ³mica - Colombia")
    print("="*70)
    
    # Paso 1: Consolidar cada mÃ³dulo a travÃ©s de los meses
    print("\nðŸ“Š PASO 1: Consolidando mÃ³dulos individuales...")
    
    modules_data = {}
    for csv_name, module_key in MODULE_NAMES.items():
        df = consolidate_module_across_months(csv_name, module_key)
        if df is not None:
            level = identify_module_level(df, module_key)
            modules_data[module_key] = {
                'data': df,
                'level': level,
                'shape': df.shape
            }
    
    # Paso 2: Hacer merge de todos los mÃ³dulos
    print("\nðŸ”— PASO 2: Uniendo todos los mÃ³dulos...")
    
    final_df = merge_all_modules(modules_data)
    
    # Paso 3: Mostrar informaciÃ³n sobre valores nulos
    print("\nðŸ“‹ PASO 3: AnÃ¡lisis de valores nulos...")
    print(f"\n{'â”€'*60}")
    
    null_counts = final_df.isnull().sum()
    null_pct = (null_counts / len(final_df) * 100).round(2)
    
    # Mostrar columnas con mÃ¡s del 50% de nulos
    high_null_cols = null_pct[null_pct > 50].sort_values(ascending=False)
    
    if len(high_null_cols) > 0:
        print(f"\nColumnas con >50% valores nulos ({len(high_null_cols)} columnas):")
        print("(Pueden ser 'No Aplica' segÃºn el mÃ³dulo)")
        for col, pct in high_null_cols.head(20).items():
            print(f"  {col}: {pct:.1f}%")
    
    print(f"\n{'='*70}")
    print("âœ… CONSOLIDACIÃ“N COMPLETADA EXITOSAMENTE")
    print(f"{'='*70}")
    print(f"\nArchivo final: {PROCESSED_DIR / 'geih_2024_consolidated.csv'}")
    print(f"Registros: {final_df.shape[0]:,}")
    print(f"Columnas: {final_df.shape[1]:,}")


if __name__ == "__main__":
    main()
